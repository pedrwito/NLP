# Procesamiento de Lenguaje Natural (NLP) - CEIA

**Autor:** Pedro Lucas Barrera  
**Carrera:** Carrera de Especializaci√≥n en Inteligencia Artificial (CEIA)  
**Materia:** Procesamiento de Lenguaje Natural  

Este repositorio contiene todos los desaf√≠os y trabajos pr√°cticos desarrollados durante el curso de NLP de la CEIA. Cada notebook implementa diferentes t√©cnicas y algoritmos fundamentales del procesamiento de lenguaje natural.

## üìÅ Estructura del Repositorio

### üìä Notebooks de Desaf√≠os

#### `desafio1_pedro_barrera.ipynb`
**Tema:** Vectorizaci√≥n de Documentos y Clasificaci√≥n con Na√Øve Bayes

**Descripci√≥n:**
Este notebook implementa t√©cnicas de vectorizaci√≥n de texto y clasificaci√≥n utilizando el dataset 20newsgroups. Se desarrollan tres puntos principales:

1. **An√°lisis de Similitud de Documentos:** Vectorizaci√≥n TF-IDF de documentos, selecci√≥n aleatoria de 5 documentos y an√°lisis de sus 5 m√°s similares usando similitud coseno.

2. **Optimizaci√≥n de Clasificadores Na√Øve Bayes:** Entrenamiento y optimizaci√≥n de modelos MultinomialNB y ComplementNB, probando diferentes configuraciones de vectorizadores y hiperpar√°metros para maximizar el F1-score macro.

3. **Similitud entre Palabras:** Transposici√≥n de la matriz documento-t√©rmino para obtener vectores de palabras y an√°lisis de similitud sem√°ntica entre t√©rminos seleccionados manualmente.

**Resultados destacados:**
- Mejor configuraci√≥n: ComplementNB con alpha=0.1 y vectorizador TF-IDF default (F1-score: 0.6954)
- An√°lisis detallado de similitudes entre palabras como 'computer', 'baseball', 'medical', 'religion' y 'car'

#### `desafio2_pedro_barrera.ipynb`
**Tema:** Word Embeddings con Gensim y Word2Vec

**Descripci√≥n:**
Implementaci√≥n de word embeddings utilizando Gensim sobre un corpus personalizado de letras de canciones de Bob Dylan. El notebook incluye:

1. **Entrenamiento de Word2Vec:** Configuraci√≥n y entrenamiento de un modelo Skip-gram con 300 dimensiones, ventana de contexto de 2 palabras y 20 negative samples.

2. **An√°lisis de Similitudes Sem√°nticas:** Exploraci√≥n de palabras similares para t√©rminos como "love", "night", "woman", "man", "truth" y "heart", analizando las relaciones sem√°nticas capturadas por el modelo.

3. **Operaciones Vectoriales:** Pruebas de combinaciones de vectores (ej: woman + love + man) para explorar relaciones sem√°nticas complejas.

4. **Visualizaci√≥n:** Mapas de calor de similitudes entre t√©rminos seleccionados y visualizaciones t-SNE en 2D y 3D de los embeddings.

**Resultados destacados:**
- Vocabulario de 948 palabras √∫nicas del corpus de Bob Dylan
- An√°lisis de patrones po√©ticos y emocionales en las similitudes sem√°nticas
- Visualizaciones interactivas de espacios de embeddings

#### `desafio3.ipynb`
**Tema:** Modelos de Lenguaje con Redes Neuronales Recurrentes

**Descripci√≥n:**
Desarrollo de un modelo de lenguaje basado en LSTM para generaci√≥n de texto usando letras de canciones de The Beatles. El notebook cubre:

1. **Preprocesamiento y Tokenizaci√≥n:** An√°lisis de distribuci√≥n de longitudes de secuencias, tokenizaci√≥n con Keras y estructuraci√≥n del dataset many-to-many.

2. **Arquitectura del Modelo:** Red neuronal con capas de Embedding, LSTM bidireccional y Dense con activaci√≥n softmax para predicci√≥n de siguiente palabra.

3. **Entrenamiento con Perplejidad:** Implementaci√≥n de callback personalizado para monitorear la perplejidad como m√©trica de calidad del modelo de lenguaje.

4. **Estrategias de Generaci√≥n:** Implementaci√≥n de diferentes t√©cnicas de generaci√≥n:
   - Greedy search (selecci√≥n determin√≠stica)
   - Beam search determin√≠stico
   - Beam search estoc√°stico con temperatura

**Resultados destacados:**
- Modelo con arquitectura LSTM de 100 unidades en dos capas
- Sistema de generaci√≥n con beam search configurable
- Interface interactiva con Gradio para pruebas del modelo

### üìÑ Archivos de Datos

#### `la_metamorfosis.txt`
Texto completo de "La Metamorfosis" de Franz Kafka en espa√±ol, utilizado como corpus de referencia para algunos ejercicios y experimentos adicionales.

## üöÄ Instrucciones de Ejecuci√≥n

### Prerrequisitos
```bash
# Instalar dependencias principales
pip install numpy pandas matplotlib seaborn scikit-learn
pip install tensorflow keras
pip install gensim
pip install gradio
pip install plotly
pip install scipy
```

### Ejecuci√≥n de los Notebooks

1. **Para el Desaf√≠o 1:**
   ```bash
   jupyter notebook desafio1_pedro_barrera.ipynb
   ```
   - No requiere datasets externos (usa 20newsgroups de sklearn)
   - Tiempo estimado de ejecuci√≥n: 15-20 minutos

2. **Para el Desaf√≠o 2:**
   ```bash
   jupyter notebook desafio2_pedro_barrera.ipynb
   ```
   - Requiere el dataset `datasets/songs_dataset/bob-dylan.txt`
   - Tiempo estimado de ejecuci√≥n: 10-15 minutos

3. **Para el Desaf√≠o 3:**
   ```bash
   jupyter notebook desafio3.ipynb
   ```
   - Descarga autom√°ticamente el dataset de canciones si no est√° presente
   - Tiempo estimado de entrenamiento: 30-45 minutos (dependiendo del hardware)
   - Incluye interface interactiva con Gradio

### Configuraci√≥n del Entorno

```bash
# Clonar el repositorio
git clone [URL_del_repositorio]
cd NLP

# Crear entorno virtual (recomendado)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt  # Si existe
# O instalar manualmente las librer√≠as listadas arriba
```

## üìà Conceptos Implementados

### T√©cnicas de NLP Cubiertas:
- ‚úÖ Vectorizaci√≥n TF-IDF
- ‚úÖ Similitud Coseno
- ‚úÖ Clasificaci√≥n con Na√Øve Bayes (Multinomial y Complement)
- ‚úÖ Word Embeddings (Word2Vec)
- ‚úÖ Modelos de Lenguaje con LSTM
- ‚úÖ Generaci√≥n de Texto (Greedy, Beam Search)
- ‚úÖ M√©tricas de Evaluaci√≥n (F1-score, Perplejidad)

### Visualizaciones:
- ‚úÖ Mapas de calor de similitudes
- ‚úÖ Distribuciones de longitudes de secuencias
- ‚úÖ Evoluci√≥n de m√©tricas durante entrenamiento
- ‚úÖ Proyecciones t-SNE de embeddings
- ‚úÖ Interfaces interactivas con Gradio

## üìö Estructura de Aprendizaje

Cada desaf√≠o est√° dise√±ado para construir sobre los conceptos anteriores:

1. **Desaf√≠o 1** ‚Üí Fundamentos de vectorizaci√≥n y clasificaci√≥n
2. **Desaf√≠o 2** ‚Üí Representaciones densas y similitud sem√°ntica
3. **Desaf√≠o 3** ‚Üí Modelos generativos y arquitecturas profundas

## üîß Notas T√©cnicas

- Los notebooks incluyen an√°lisis detallados de resultados y conclusiones
- Se utilizan t√©cnicas de reproducibilidad (semillas aleatorias)
- El c√≥digo est√° documentado y comentado en espa√±ol
- Se incluyen callbacks personalizados para monitoreo de entrenamiento
- Las visualizaciones son interactivas cuando es posible

## üìù Licencia

Este material es parte del trabajo acad√©mico para la CEIA y est√° destinado √∫nicamente a fines educativos.

---

Para cualquier consulta o problema con la ejecuci√≥n de los notebooks, revisar los comentarios dentro de cada archivo o contactar al autor. 