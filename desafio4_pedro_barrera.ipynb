{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM Bot QA\n",
    "\n",
    "### Pedro Lucas Barrera - a1801"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqO0PRcFsPTe"
   },
   "source": [
    "### Datos\n",
    "El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n",
    "[LINK](http://convai.io/data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bDFC0I3j9oFD"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cq3YXak9sGHd"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, SimpleRNN\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer, text_to_word_sequence\n",
    "from keras.layers import Input\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RHNkUaPp6aYq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download\n",
      "To: /Users/pedrobarrera/procesamiento_lenguaje_natural/data_volunteers.json\n",
      "100%|██████████| 2.58M/2.58M [00:00<00:00, 16.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Descargar la carpeta de dataset\n",
    "import os\n",
    "import gdown\n",
    "if os.access('data_volunteers.json', os.F_OK) is False:\n",
    "    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n",
    "    output = 'data_volunteers.json'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "else:\n",
    "    print(\"El dataset ya se encuentra descargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WZy1-wgG-Rp7"
   },
   "outputs": [],
   "source": [
    "# dataset_file\n",
    "import json\n",
    "\n",
    "text_file = \"data_volunteers.json\"\n",
    "with open(text_file) as f:\n",
    "    data = json.load(f) # la variable data será un diccionario\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ue5qd54S-eew"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observar los campos disponibles en cada linea del dataset\n",
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jHBRAXPl-3dz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows utilizadas: 6033\n"
     ]
    }
   ],
   "source": [
    "chat_in = []\n",
    "chat_out = []\n",
    "\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "max_len = 30\n",
    "\n",
    "def clean_text(txt):\n",
    "    txt = txt.lower()    \n",
    "    txt.replace(\"\\'d\", \" had\")\n",
    "    txt.replace(\"\\'s\", \" is\")\n",
    "    txt.replace(\"\\'m\", \" am\")\n",
    "    txt.replace(\"don't\", \"do not\")\n",
    "    txt = re.sub(r'\\W+', ' ', txt)\n",
    "    \n",
    "    return txt\n",
    "\n",
    "for line in data:\n",
    "    for i in range(len(line['dialog'])-1):\n",
    "        # vamos separando el texto en \"preguntas\" (chat_in)\n",
    "        # y \"respuestas\" (chat_out)\n",
    "        chat_in = clean_text(line['dialog'][i]['text'])\n",
    "        chat_out = clean_text(line['dialog'][i+1]['text'])\n",
    "\n",
    "        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n",
    "            continue\n",
    "\n",
    "        input_sentence, output = chat_in, chat_out\n",
    "        \n",
    "        # output sentence (decoder_output) tiene <eos>\n",
    "        output_sentence = output + ' <eos>'\n",
    "        # output sentence input (decoder_input) tiene <sos>\n",
    "        output_sentence_input = '<sos> ' + output\n",
    "\n",
    "        input_sentences.append(input_sentence)\n",
    "        output_sentences.append(output_sentence)\n",
    "        output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "07L1qj8pC_l6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences[1], output_sentences[1], output_sentences_inputs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P-ynUNP5xp6"
   },
   "source": [
    "### 2 - Preprocesamiento\n",
    "Realizar el preprocesamiento necesario para obtener:\n",
    "- word2idx_inputs, max_input_len\n",
    "- word2idx_outputs, max_out_len, num_words_output\n",
    "- encoder_input_sequences, decoder_output_sequences, decoder_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decido usar un tokenizer distinto para input y output dado que output posee \"sos\" y \"eos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por el limite de recursos, en caso de que sean muchas\n",
    "MAX_VOCAB_SIZE = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tokenizers\n",
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "\n",
    "# Fit en los datos\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] +output_sentences)\n",
    "\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario de input: 1799\n",
      "Sentencia de entrada más larga: 9\n"
     ]
    }
   ],
   "source": [
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario de input:\", len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Sentencia de entrada más larga:\", max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario de output: 1806\n",
      "Sentencia de salida más larga: 10\n"
     ]
    }
   ],
   "source": [
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario de output:\", len(word2idx_outputs))\n",
    "\n",
    "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Sentencia de salida más larga:\", max_out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_sequences shape: (6033, 9)\n",
      "decoder_input_sequences shape: (6033, 10)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6033, 10, 1807)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n",
    "decoder_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CJIsLBbj6rg"
   },
   "source": [
    "### 3 - Preparar los embeddings\n",
    "Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando FastText embeddings (1.6 GB)...\n",
      "Esto puede tomar 5-15 minutos...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1264M  100 1264M    0     0  21.0M      0  0:01:00  0:01:00 --:--:-- 21.4M\n",
      "✅ Descarga completada!\n",
      "Archivo listo: 2000000 300\n"
     ]
    }
   ],
   "source": [
    "# Para descargar los embeddings de fasttext se consigui el codigo usando ia generativa, con el siguiente prompt:\n",
    "# Dame un codigo simple para descargar los embeddings 'cc.en.300.vec' FastText\n",
    "import os\n",
    "\n",
    "# Verificar si ya existe\n",
    "if os.path.exists('cc.en.300.vec'):\n",
    "    print(\"✅ Embeddings ya descargados\")\n",
    "else:\n",
    "    print(\"Descargando FastText embeddings (1.6 GB)...\")\n",
    "    print(\"Esto puede tomar 5-15 minutos...\")\n",
    "    \n",
    "    # Descargar con curl (el más confiable)\n",
    "    !curl -L -o cc.en.300.vec.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
    "    \n",
    "    # Descomprimir\n",
    "    !gunzip cc.en.300.vec.gz\n",
    "    \n",
    "    print(\"✅ Descarga completada!\")\n",
    "\n",
    "# Verificar que funciona\n",
    "if os.path.exists('cc.en.300.vec'):\n",
    "    with open('cc.en.300.vec', 'r') as f:\n",
    "        first_line = f.readline().strip()\n",
    "        print(f\"Archivo listo: {first_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import pickle\n",
    "\n",
    "class WordsEmbeddings(object):\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __init__(self):\n",
    "        # load the embeddings\n",
    "        words_embedding_pkl = Path(self.PKL_PATH)\n",
    "        if not words_embedding_pkl.is_file():\n",
    "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
    "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
    "            embeddings = self.convert_model_to_pickle()\n",
    "        else:\n",
    "            embeddings = self.load_model_from_pickle()\n",
    "        self.embeddings = embeddings\n",
    "        # build the vocabulary hashmap\n",
    "        index = np.arange(self.embeddings.shape[0])\n",
    "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
    "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
    "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
    "\n",
    "    def get_words_embeddings(self, words):\n",
    "        words_idxs = self.words2idxs(words)\n",
    "        return self.embeddings[words_idxs]['embedding']\n",
    "\n",
    "    def words2idxs(self, words):\n",
    "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
    "\n",
    "    def idxs2words(self, idxs):\n",
    "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
    "\n",
    "    def load_model_from_pickle(self):\n",
    "        self.logger.debug(\n",
    "            'loading words embeddings from pickle {}'.format(\n",
    "                self.PKL_PATH\n",
    "            )\n",
    "        )\n",
    "        max_bytes = 2**28 - 1 # 256MB\n",
    "        bytes_in = bytearray(0)\n",
    "        input_size = os.path.getsize(self.PKL_PATH)\n",
    "        with open(self.PKL_PATH, 'rb') as f_in:\n",
    "            for _ in range(0, input_size, max_bytes):\n",
    "                bytes_in += f_in.read(max_bytes)\n",
    "        embeddings = pickle.loads(bytes_in)\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "    def convert_model_to_pickle(self):\n",
    "        # create a numpy strctured array:\n",
    "        # word     embedding\n",
    "        # U50      np.float32[]\n",
    "        # word_1   a, b, c\n",
    "        # word_2   d, e, f\n",
    "        # ...\n",
    "        # word_n   g, h, i\n",
    "        self.logger.debug(\n",
    "            'converting and loading words embeddings from text file {}'.format(\n",
    "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
    "            )\n",
    "        )\n",
    "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
    "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
    "        structure = np.dtype(structure)\n",
    "        # load numpy array from disk using a generator\n",
    "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
    "            embeddings_gen = (\n",
    "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
    "                if len(line.split()[1:]) == self.N_FEATURES\n",
    "            )\n",
    "            embeddings = np.fromiter(embeddings_gen, structure)\n",
    "        # add a null embedding\n",
    "        null_embedding = np.array(\n",
    "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
    "            dtype=structure\n",
    "        )\n",
    "        embeddings = np.concatenate([embeddings, null_embedding])\n",
    "        # dump numpy array to disk using pickle\n",
    "        max_bytes = 2**28 - 1 # # 256MB\n",
    "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(self.PKL_PATH, 'wb') as f_out:\n",
    "            for idx in range(0, len(bytes_out), max_bytes):\n",
    "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class FasttextEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
    "    PKL_PATH = 'fasttext.pkl'\n",
    "    N_FEATURES = 300\n",
    "    WORD_MAX_SIZE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embeddings = FasttextEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing embedding matrix...\n",
      "number of null word embeddings: 1\n"
     ]
    }
   ],
   "source": [
    "# Crear la Embedding matrix de las secuencias\n",
    "# en inglés\n",
    "\n",
    "print('preparing embedding matrix...')\n",
    "embed_dim = model_embeddings.N_FEATURES\n",
    "words_not_found = []\n",
    "\n",
    "# word_index provieen del tokenizer\n",
    "\n",
    "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs) + 1) # vocab_size\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        \n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        words_not_found.append(word)\n",
    "\n",
    "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix**2, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vKbhjtIwPgM"
   },
   "source": [
    "### 4 - Entrenar el modelo\n",
    "Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrobarrera/procesamiento_lenguaje_natural/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">540,000</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">231,296</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">219,648</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1807</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">233,103</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m300\u001b[0m)    │    \u001b[38;5;34m540,000\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m231,296\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │    \u001b[38;5;34m219,648\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m), │    \u001b[38;5;34m131,584\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1807\u001b[0m)  │    \u001b[38;5;34m233,103\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,355,631</span> (5.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,355,631\u001b[0m (5.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">815,631</span> (3.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m815,631\u001b[0m (3.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">540,000</span> (2.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m540,000\u001b[0m (2.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_units = 128\n",
    "\n",
    "# define training encoder\n",
    "encoder_inputs = Input(shape=(max_input_len,))\n",
    "\n",
    "#encoder_embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)\n",
    "\n",
    "encoder_embedding_layer = Embedding(\n",
    "          input_dim=nb_words,  # definido en el Tokenizador\n",
    "          output_dim=embed_dim,  # dimensión de los embeddings utilizados\n",
    "          input_length=max_input_len, # tamaño máximo de la secuencia de entrada\n",
    "          weights=[embedding_matrix],  # matrix de embeddings\n",
    "          trainable=False)      # marcar como layer no entrenable\n",
    "\n",
    "encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "encoder = LSTM(n_units, return_state=True, dropout=0.2)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# define training decoder\n",
    "decoder_inputs = Input(shape=(max_out_len,))\n",
    "decoder_embedding_layer = Embedding(input_dim=num_words_output, output_dim=n_units, input_length=max_out_len)\n",
    "decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True, dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "\n",
    "# Dense\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "# Modelo completo (encoder+decoder) para poder entrenar\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "# Modelo solo encoder\n",
    "\n",
    "# define inference encoder\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "plot_model(encoder_model, to_file='encoder_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "# Modelo solo decoder (para realizar inferencia)\n",
    "\n",
    "# define inference decoder\n",
    "decoder_state_input_h = Input(shape=(n_units,))\n",
    "decoder_state_input_c = Input(shape=(n_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# En cada predicción habrá una sola palabra de entrada al decoder,\n",
    "# que es la realimentación de la palabra anterior\n",
    "# por lo que hay que modificar el input shape de la layer de Embedding\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "plot_model(decoder_model, to_file='decoder_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.5434 - loss: 2.9260 - val_accuracy: 0.6322 - val_loss: 2.2462\n",
      "Epoch 2/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.6293 - loss: 2.0406 - val_accuracy: 0.6661 - val_loss: 2.0604\n",
      "Epoch 3/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.6841 - loss: 1.7981 - val_accuracy: 0.6862 - val_loss: 1.9154\n",
      "Epoch 4/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.7109 - loss: 1.6418 - val_accuracy: 0.7005 - val_loss: 1.8323\n",
      "Epoch 5/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.7235 - loss: 1.5397 - val_accuracy: 0.7073 - val_loss: 1.7838\n",
      "Epoch 6/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.7310 - loss: 1.4687 - val_accuracy: 0.7122 - val_loss: 1.7482\n",
      "Epoch 7/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7377 - loss: 1.4137 - val_accuracy: 0.7141 - val_loss: 1.7209\n",
      "Epoch 8/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.7407 - loss: 1.3684 - val_accuracy: 0.7167 - val_loss: 1.6977\n",
      "Epoch 9/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.7455 - loss: 1.3284 - val_accuracy: 0.7186 - val_loss: 1.6899\n",
      "Epoch 10/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.7492 - loss: 1.2948 - val_accuracy: 0.7221 - val_loss: 1.6774\n",
      "Epoch 11/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.7532 - loss: 1.2634 - val_accuracy: 0.7233 - val_loss: 1.6632\n",
      "Epoch 12/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7568 - loss: 1.2356 - val_accuracy: 0.7250 - val_loss: 1.6565\n",
      "Epoch 13/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7594 - loss: 1.2105 - val_accuracy: 0.7275 - val_loss: 1.6516\n",
      "Epoch 14/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.7613 - loss: 1.1868 - val_accuracy: 0.7303 - val_loss: 1.6483\n",
      "Epoch 15/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.7638 - loss: 1.1650 - val_accuracy: 0.7309 - val_loss: 1.6466\n",
      "Epoch 16/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.7662 - loss: 1.1434 - val_accuracy: 0.7321 - val_loss: 1.6436\n",
      "Epoch 17/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7682 - loss: 1.1230 - val_accuracy: 0.7326 - val_loss: 1.6420\n",
      "Epoch 18/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.7707 - loss: 1.1050 - val_accuracy: 0.7337 - val_loss: 1.6407\n",
      "Epoch 19/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.7726 - loss: 1.0857 - val_accuracy: 0.7350 - val_loss: 1.6436\n",
      "Epoch 20/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.7740 - loss: 1.0680 - val_accuracy: 0.7332 - val_loss: 1.6456\n",
      "Epoch 21/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.7763 - loss: 1.0521 - val_accuracy: 0.7334 - val_loss: 1.6447\n",
      "Epoch 22/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.7789 - loss: 1.0350 - val_accuracy: 0.7353 - val_loss: 1.6518\n",
      "Epoch 23/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.7808 - loss: 1.0204 - val_accuracy: 0.7329 - val_loss: 1.6556\n",
      "Epoch 24/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.7828 - loss: 1.0052 - val_accuracy: 0.7370 - val_loss: 1.6554\n",
      "Epoch 25/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.7841 - loss: 0.9901 - val_accuracy: 0.7350 - val_loss: 1.6641\n",
      "Epoch 26/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7865 - loss: 0.9780 - val_accuracy: 0.7355 - val_loss: 1.6652\n",
      "Epoch 27/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.7885 - loss: 0.9638 - val_accuracy: 0.7368 - val_loss: 1.6717\n",
      "Epoch 28/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.7900 - loss: 0.9509 - val_accuracy: 0.7358 - val_loss: 1.6765\n",
      "Epoch 29/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.7908 - loss: 0.9395 - val_accuracy: 0.7355 - val_loss: 1.6772\n",
      "Epoch 30/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.7943 - loss: 0.9258 - val_accuracy: 0.7360 - val_loss: 1.6824\n",
      "Epoch 31/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.7959 - loss: 0.9131 - val_accuracy: 0.7386 - val_loss: 1.6893\n",
      "Epoch 32/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.7980 - loss: 0.9020 - val_accuracy: 0.7351 - val_loss: 1.6955\n",
      "Epoch 33/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.7990 - loss: 0.8907 - val_accuracy: 0.7368 - val_loss: 1.6983\n",
      "Epoch 34/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8002 - loss: 0.8794 - val_accuracy: 0.7360 - val_loss: 1.7048\n",
      "Epoch 35/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.8021 - loss: 0.8697 - val_accuracy: 0.7360 - val_loss: 1.7100\n",
      "Epoch 36/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.8039 - loss: 0.8595 - val_accuracy: 0.7366 - val_loss: 1.7193\n",
      "Epoch 37/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8036 - loss: 0.8505 - val_accuracy: 0.7363 - val_loss: 1.7242\n",
      "Epoch 38/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8056 - loss: 0.8412 - val_accuracy: 0.7370 - val_loss: 1.7313\n",
      "Epoch 39/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8069 - loss: 0.8311 - val_accuracy: 0.7375 - val_loss: 1.7348\n",
      "Epoch 40/40\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8091 - loss: 0.8205 - val_accuracy: 0.7346 - val_loss: 1.7450\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_targets,\n",
    "    epochs=40, \n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zbwn0ekDy_s2"
   },
   "source": [
    "### 5 - Inferencia\n",
    "Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armar los conversores de índice a palabra:\n",
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens especiales en word2idx_outputs:\n",
      "❌ '<sos>': No encontrado\n",
      "❌ '<eos>': No encontrado\n",
      "✅ 'sos': 815\n",
      "✅ 'eos': 1\n",
      "\n",
      "Primeras 10 palabras en vocabulario: ['eos', 'you', 'i', 'do', 'what', 'a', 'are', 'to', 'for', 'how']\n"
     ]
    }
   ],
   "source": [
    "# Verificar qué tokens tienes en el vocabulario\n",
    "print(\"Tokens especiales en word2idx_outputs:\")\n",
    "special_tokens = ['<sos>', '<eos>', 'sos', 'eos']\n",
    "for token in special_tokens:\n",
    "    if token in word2idx_outputs:\n",
    "        print(f\"✅ '{token}': {word2idx_outputs[token]}\")\n",
    "    else:\n",
    "        print(f\"❌ '{token}': No encontrado\")\n",
    "\n",
    "print(f\"\\nPrimeras 10 palabras en vocabulario: {list(word2idx_outputs.keys())[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que por el normalizado o tokenizado, se eliminaron erroneamente los caracteres <>. Por esto tomaremos como principio y final de frase los placeholders sos y eso sin los <>. la siguiente funcion genera una respuesta del chatbot dada una secuencia de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_response(input_text):\n",
    "\n",
    "    # Preprocess the input text (same as training data)\n",
    "    input_text_clean = clean_text(input_text)\n",
    "    \n",
    "    # Convert to sequence\n",
    "    input_seq = input_tokenizer.texts_to_sequences([input_text_clean])\n",
    "    input_seq = pad_sequences(input_seq, maxlen=max_input_len)\n",
    "    \n",
    "    # Get encoder states\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "\n",
    "    # Initialize decoder input with \"sos\"\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['sos']\n",
    "\n",
    "    # Get the end token index\n",
    "    eos = word2idx_outputs['eos']\n",
    "    \n",
    "    response_words = []\n",
    "    for _ in range(max_out_len):\n",
    "        # Predict next token\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n",
    "        predicted_idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        # Stop if we hit end of sentence\n",
    "        if eos == predicted_idx:\n",
    "            break\n",
    "\n",
    "        # Convert index to word\n",
    "        if predicted_idx > 0:\n",
    "            word = idx2word_target[predicted_idx]\n",
    "            response_words.append(word)\n",
    "\n",
    "        # Update states for next prediction\n",
    "        states_value = [h, c]\n",
    "        \n",
    "        # Update decoder input\n",
    "        target_seq[0, 0] = predicted_idx\n",
    "\n",
    "    return ' '.join(response_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testeo el chatbot con frases de ejemplo recomendadas y otras agregadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:\n",
      "----------------------------------\n",
      "User: Do you read?\n",
      "Bot:  i like to go to the beach\n",
      "----------------------------------\n",
      "User: Do you have any pet?\n",
      "Bot:  i like to go to the beach\n",
      "----------------------------------\n",
      "User: Where are you from?\n",
      "Bot:  i am a vegan i am a vegan\n",
      "----------------------------------\n",
      "User: Hi how are you?\n",
      "Bot:  i am fine and you\n",
      "----------------------------------\n",
      "User: What do you like to do?\n",
      "Bot:  i like to go to the beach\n",
      "----------------------------------\n",
      "User: Whats your name?\n",
      "Bot:  i am a student\n",
      "----------------------------------\n",
      "User: Are you ok?\n",
      "Bot:  i am a student\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "def test_chatbot():\n",
    "\n",
    "    test_questions = [\n",
    "        \"Do you read?\",\n",
    "        \"Do you have any pet?\", \n",
    "        \"Where are you from?\",\n",
    "        \"Hi how are you?\",\n",
    "        \"What do you like to do?\",\n",
    "        \"Whats your name?\",\n",
    "        \"Are you ok?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Test:\")\n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "    for question in test_questions:\n",
    "        response = chat_response(question)\n",
    "        print(f\"User: {question}\")\n",
    "        print(f\"Bot:  {response}\")\n",
    "        print(\"----------------------------------\")\n",
    "\n",
    "# Run the test\n",
    "test_chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida es repetitiva en muchos casos y repite frases como 'I am vegan', 'i like to go to the beach', o 'i am a student' lo que indica que el modelo no esta funcionando bien, dado que genera respuestas repetitivas y sin sentido. Esto es extraño dado que en el entrenamiento se habian alcanzado accuracies de validacion del 75% y de train del 80%. Podria deberse a una falta de datos que haga que el set entrenamiento no sea lo suficientemente representativo. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
